{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f2fde0-a61c-4cdb-84d0-b8ecbe870e58",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "380bc1a8-2c56-4e5c-a2bb-81284df75ccb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tokenizers 0.13.3\n",
      "Uninstalling tokenizers-0.13.3:\n",
      "  Successfully uninstalled tokenizers-0.13.3\n",
      "Requirement already satisfied: transformers in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (4.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (1.25.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.13.3\n",
      "Requirement already satisfied: tokenizers in /home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages (0.13.3)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tokenizers -y \n",
    "!pip install transformers\n",
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e578a4d-3344-4951-8e55-f16058d5f6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb006d-dc0a-4c42-a46d-71b8bd91e72b",
   "metadata": {},
   "source": [
    "## Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160c5688-62ce-4748-85c3-625be1a94ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac08eeebd7b431fa0295714ddf2654e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ce6e6f96c74685a6ab414dd56c5cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435a43b89e4b4c71b36608831a7be4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ed1a7d67064092933c15f7db105abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = pipeline(\"sentiment-analysis\")\n",
    "result = clf(\"what a beautiful daty!\")[0]\n",
    "print(\"Sentimental Analysis result: %s, Sentiment score: %0.4f\" % (result['label'], result['score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b99c3-f623-490f-83dc-819ae3cd00a0",
   "metadata": {},
   "source": [
    "## Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69dd9f59-79bd-4186-8ff3-c9cb1317ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b135abf4a5b4ccb9bf046b34d504338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78863a3a767442e181e02a09de85e784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056ac58151674b05aaed2669bd45e5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019a1795b98940efb0641d67b6541d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd37414ab3b49ac83b6b574d66df886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/studio-lab-user/.conda/envs/d2l/lib/python3.9/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and she was a woman. What about if she was married like that? But she was a woman for a very long time, with her sister.\n",
      "\n",
      "\"And\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\"text-generation\")\n",
    "result = text_generator(\"Alice was beginning to get very tired of sitting by her sister on the bank,\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5785bec-bf09-4c41-9ccd-94d48ebeefa4",
   "metadata": {},
   "source": [
    "## AutoClasses and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f2b7cd-1a03-44ed-9139-c4bd1cc13aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42c3980-e3f2-4821-88ae-49825c802a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283a940eb0164a56a49d46a9ca609836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e606ca008b94251b84e66771e8297c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05f149ac5b944c99f59b7d900912bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051e52f616154f26bf34dfdaba7bc8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f7eef-839b-4799-81bc-756eecd0adef",
   "metadata": {},
   "source": [
    "### Provide very similar text from GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "018d8067-70a6-46aa-b50e-1c791813bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence =\"She swiftly navigated through the bustling city streets.\"\n",
    "target_sequence = \"She deftly maneuvered amidst the crowded urban roads.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626bd63-3ece-4eb4-86ff-6451e5d4fdab",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee9fbb54-9931-4fa4-9086-0b5821969b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(input_sentence, target_sequence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e53a831-4423-4d6f-9a0e-1c589ad79cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(**tokens).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0475767-d132-40d3-8f7d-13fa02fc7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.softmax(logits, dim=1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75615bee-4b99-49e6-af60-61058f0cea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no: 11%\n",
      "yes: 89%\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(['no', 'yes']):\n",
    "    print(f\"{label}: {int(round(results[i] * 100))}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afe3c676-ef9f-43b8-89ee-fe954a426c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no: 77%\n",
      "yes: 23%\n"
     ]
    }
   ],
   "source": [
    "target_sequence = \"He got lost in the tranquility of the quiet country lanes.\"\n",
    "tokens = tokenizer(input_sentence, target_sequence, return_tensors=\"pt\")\n",
    "logits = model(**tokens).logits\n",
    "result = torch.softmax(logits, dim=1).tolist()[0]\n",
    "\n",
    "for i, label in enumerate(['no', 'yes']):\n",
    "    print(f\"{label}: {int(round(result[i] * 100))}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc11e2-1589-4409-8ff4-5a1882c70118",
   "metadata": {},
   "source": [
    "## movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8f541c1-15c0-48d3-881a-2708a0596bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "fileids = movie_reviews.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42841ba0-4b07-42d6-a9c8-28c546dea6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids]\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51c72801-11d4-453b-885b-178712b5bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'pos':1, 'neg':0}\n",
    "y = np.array([label_dict[c] for c in categories])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, y, test_size = 0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69391108-3bae-4321-8a9a-2283a441d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a866561-13e1-4a93-9fea-a442b5822072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba388147-0463-4950-9b6f-a76d81af741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ef2f487-1066-442a-a9b1-1c37036fb6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d29be88f-66c9-42b6-8fd5-60250fb3b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "y_pred = []\n",
    "num_batch = len(y_test)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d57c3c48-4303-4c9b-8203-7f7a5f608eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK score: 0.8425\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_batch):\n",
    "    inputs = tokenizer(\n",
    "        X_test[i*batch_size:(i+1)*batch_size],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    logits = model(**inputs).logits\n",
    "    pred = F.softmax(logits, dim=-1)\n",
    "    results = pred.cpu().detach().numpy().argmax(axis=1)\n",
    "    y_pred.extend(results.tolist())\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "score = sum(y_test ==np.array(y_pred))/len(y_test)\n",
    "print(\"NLTK score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11767508-f398-40f1-acb8-2e2352b27731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995786dd-d1a0-4460-bea2-b279c95d10e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fb233-3bc6-443b-9845-4b9016c8b639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86dc1b-1f7d-4b34-8e42-4b4bb1128aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
